{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Heart Disease with Amazon SageMaker Linear Learner\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.7/site-packages (0.1.35)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.19.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.23.0,>=1.22.3 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.22.3)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# cell 00 .. install and setup dependent libraries and SDKs for Jupyter Notebook\n",
    "%pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-2-645411899653\n"
     ]
    }
   ],
   "source": [
    "# cell 01\n",
    "import sagemaker\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "session = sagemaker.Session()\n",
    "s3_bucket = session.default_bucket()\n",
    "s3_data_prefix = 'sagemaker/heartdisease/data/'\n",
    "s3_model_prefix = 'sagemaker/heartdisease/linearlearner'\n",
    "algorithm = 'linear-learner'\n",
    "trial_prefix = 'sm-heart-ll-trial'\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker',region_name=region)\n",
    "s3 = boto3.Session().resource('s3')\n",
    "\n",
    "print(s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02 ... ETL\n",
    "s3_remote_path = s3_data_prefix + 'heart_failure_clinical_records_data-02-processed.csv'\n",
    "sm_local_path = 'heart_failure_clinical_records_data-02-processed.csv'\n",
    "\n",
    "# download file from remote to local\n",
    "s3.Bucket(s3_bucket).download_file( s3_remote_path, sm_local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_heart_failure</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>age</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.192945</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>1.681648e-02</td>\n",
       "      <td>0.490057</td>\n",
       "      <td>-1.504036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.491279</td>\n",
       "      <td>7.514640</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>7.535660e-09</td>\n",
       "      <td>-0.284552</td>\n",
       "      <td>-0.141976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>-0.449939</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>-1.038073e+00</td>\n",
       "      <td>-0.090900</td>\n",
       "      <td>-1.731046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.912335</td>\n",
       "      <td>-0.486071</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>-5.464741e-01</td>\n",
       "      <td>0.490057</td>\n",
       "      <td>0.085034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>-0.435486</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>6.517986e-01</td>\n",
       "      <td>1.264666</td>\n",
       "      <td>-4.682176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098199</td>\n",
       "      <td>-0.537688</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>-1.109765e+00</td>\n",
       "      <td>-0.284552</td>\n",
       "      <td>1.447094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.491279</td>\n",
       "      <td>1.278215</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>6.802472e-02</td>\n",
       "      <td>-0.187726</td>\n",
       "      <td>0.539054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.333392</td>\n",
       "      <td>1.525979</td>\n",
       "      <td>1.854958</td>\n",
       "      <td>4.902082e+00</td>\n",
       "      <td>-0.575031</td>\n",
       "      <td>0.312044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.333392</td>\n",
       "      <td>1.890398</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>-1.263389e+00</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.766064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.912335</td>\n",
       "      <td>-0.398321</td>\n",
       "      <td>0.585389</td>\n",
       "      <td>1.348231e+00</td>\n",
       "      <td>0.199578</td>\n",
       "      <td>-0.141976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target_heart_failure  sex  smoking  diabetes  anaemia  \\\n",
       "0                       1    1        0         0        0   \n",
       "1                       1    1        0         0        0   \n",
       "2                       1    1        1         0        0   \n",
       "3                       1    1        0         0        1   \n",
       "4                       1    0        0         1        1   \n",
       "..                    ...  ...      ...       ...      ...   \n",
       "294                     0    1        1         1        0   \n",
       "295                     0    0        0         0        0   \n",
       "296                     0    0        0         1        0   \n",
       "297                     0    1        1         0        0   \n",
       "298                     0    1        1         0        0   \n",
       "\n",
       "     high_blood_pressure       age  creatinine_phosphokinase  \\\n",
       "0                      1  1.192945                  0.000166   \n",
       "1                      0 -0.491279                  7.514640   \n",
       "2                      0  0.350833                 -0.449939   \n",
       "3                      0 -0.912335                 -0.486071   \n",
       "4                      0  0.350833                 -0.435486   \n",
       "..                   ...       ...                       ...   \n",
       "294                    1  0.098199                 -0.537688   \n",
       "295                    0 -0.491279                  1.278215   \n",
       "296                    0 -1.333392                  1.525979   \n",
       "297                    0 -1.333392                  1.890398   \n",
       "298                    0 -0.912335                 -0.398321   \n",
       "\n",
       "     ejection_fraction     platelets  serum_creatinine  serum_sodium  \n",
       "0            -1.530560  1.681648e-02          0.490057     -1.504036  \n",
       "1            -0.007077  7.535660e-09         -0.284552     -0.141976  \n",
       "2            -1.530560 -1.038073e+00         -0.090900     -1.731046  \n",
       "3            -1.530560 -5.464741e-01          0.490057      0.085034  \n",
       "4            -1.530560  6.517986e-01          1.264666     -4.682176  \n",
       "..                 ...           ...               ...           ...  \n",
       "294          -0.007077 -1.109765e+00         -0.284552      1.447094  \n",
       "295          -0.007077  6.802472e-02         -0.187726      0.539054  \n",
       "296           1.854958  4.902082e+00         -0.575031      0.312044  \n",
       "297          -0.007077 -1.263389e+00          0.005926      0.766064  \n",
       "298           0.585389  1.348231e+00          0.199578     -0.141976  \n",
       "\n",
       "[299 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 03 ... preview input data frame ... 299 rows x 12 columns\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(sm_local_path)\n",
    "pd.set_option('display.max_columns', 50)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 50)         # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 04 ... split data set into training and test subsets\n",
    "train_data = data.sample(frac=0.8,random_state=200)\n",
    "\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data uploaded to: s3://sagemaker-us-east-2-645411899653/sagemaker/heartdisease/linearlearner/train/train_data.csv\n",
      "Test data uploaded to: s3://sagemaker-us-east-2-645411899653/sagemaker/heartdisease/linearlearner/test/test_data.csv\n"
     ]
    }
   ],
   "source": [
    "# cell 05 .. publish training and test subsets of data to S3\n",
    "train_file = 'train_data.csv';\n",
    "train_data.to_csv(train_file, index=False, header=False)\n",
    "train_data_s3_path = session.upload_data(path=train_file, key_prefix=s3_model_prefix + \"/train\")\n",
    "print('Train data uploaded to: ' + train_data_s3_path)\n",
    "\n",
    "test_file = 'test_data.csv';\n",
    "test_data.to_csv(test_file, index=False, header=False)\n",
    "test_data_s3_path = session.upload_data(path=test_file, key_prefix=s3_model_prefix + \"/test\")\n",
    "print('Test data uploaded to: ' + test_data_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the SageMaker HyperParameter Tuning Job<a name=\"Launching\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm-heart-exp-2021-12-02-21-04-17\n",
      "sm-heart-ll-trial-2021-12-02-21-04-17\n"
     ]
    }
   ],
   "source": [
    "# cell 06 ... create parent experiment to associate with HPO tuning job\n",
    "\n",
    "import time\n",
    "from time import strftime\n",
    "\n",
    "import smexperiments\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "experiment_prefix = 'sm-heart-exp' \n",
    "experiment_name = 'sm-heart-exp-{}'.format(create_date)\n",
    "trial_name = '{}-{}'.format(trial_prefix, create_date)\n",
    "\n",
    "# experiment\n",
    "try:\n",
    "    experiment = Experiment.load(experiment_name = experiment_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        experiment = Experiment.create(experiment_name = experiment_name, \n",
    "                                       description = \"SageMaker Heart Disease experiment\", \n",
    "                                       tags = [{'Key': 'Experiment', 'Value': experiment_name}])\n",
    "# trial\n",
    "\n",
    "try:\n",
    "    trial = Trial.load(trial_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        trial = Trial.create(experiment_name=experiment_name, trial_name=trial_name)\n",
    "        \n",
    "print(experiment_name)\n",
    "print(trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "WARNING:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined ML model estimator for sm-heart-ll-trial-2021-12-02-21-04-17\n"
     ]
    }
   ],
   "source": [
    "# cell 07\n",
    "# get algo container [class]\n",
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework=algorithm, version='latest')\n",
    "# setup estimator for algo [tbt running instance of algo class]\n",
    "ml_model = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(s3_bucket, s3_model_prefix),\n",
    "                                    sagemaker_session=session,\n",
    "                                    tags = [{'Key':'Experiment','Value':experiment_name},{'Key':'Trial','Value':trial_name}])\n",
    "# setup training and test/validation channels\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(s3_bucket, s3_model_prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/test/'.format(s3_bucket, s3_model_prefix), content_type='csv')\n",
    "print('Defined ML model estimator for {}'.format(trial_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sm-heart-ll-trial-211202-2118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined ML model HPO job for sm-heart-ll-trial\n",
      ".....................................................*\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for HyperParameterTuning job sm-heart-ll-trial-211202-2118: Failed. Reason: All training jobs failed. Please take a look at the training jobs failures to get more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e10733a0febd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# job.Run()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mml_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_validation\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_tuning_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_with_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_cls_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m         \u001b[0;34m\"\"\"Placeholder docstring.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_tuning_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_tuning_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   3199\u001b[0m         \"\"\"\n\u001b[1;32m   3200\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wait_until\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_tuning_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperParameterTuningJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3282\u001b[0m                 ),\n\u001b[1;32m   3283\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3284\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3285\u001b[0m             )\n\u001b[1;32m   3286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for HyperParameterTuning job sm-heart-ll-trial-211202-2118: Failed. Reason: All training jobs failed. Please take a look at the training jobs failures to get more details."
     ]
    }
   ],
   "source": [
    "#cell 08 ... HPO.Job.Run()\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "ml_model.set_hyperparameters( num_classes=2, predictor_type='binary_classifier', loss='auto', epochs=10, optimizer='sgd',mini_batch_size=100)\n",
    "\n",
    "# define hyperparameter ranges\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner-tuning.html ... L1 penalty term, learning rate\n",
    "hyperparameter_ranges = {\n",
    "                            'l1': ContinuousParameter(0.1, 1),\n",
    "                            'learning_rate': ContinuousParameter(0.1, 1)\n",
    "                        }\n",
    "\n",
    "# define metric ... F1 = harmonic mean of precision and recall\n",
    "objective_metric_name = 'validation:binary_f_beta'\n",
    "\n",
    "# define HPO job\n",
    "ml_tuner = HyperparameterTuner(ml_model,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=1,\n",
    "                            max_parallel_jobs=1,\n",
    "                            base_tuning_job_name = trial_prefix,\n",
    "                           tags = [{'Key':'Experiment','Value':experiment_name},{'Key':'Trial','Value':trial_name}])\n",
    "\n",
    "print('Defined ML model HPO job for {}'.format(trial_prefix))\n",
    "\n",
    "# job.Run()\n",
    "ml_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tuning jobs.\n",
      "Found 5 trial components.\n",
      "Associating trial component sm-heart-xgb-trial-211126-1944-004-86a1346e-aws-training-job with trial sm-heart-xgb-trial-2021-11-26-19-42-58.\n",
      "Associating trial component sm-heart-xgb-trial-211126-1944-005-7c5456b5-aws-training-job with trial sm-heart-xgb-trial-2021-11-26-19-42-58.\n",
      "Associating trial component sm-heart-xgb-trial-211126-1944-001-f61309af-aws-training-job with trial sm-heart-xgb-trial-2021-11-26-19-42-58.\n",
      "Associating trial component sm-heart-xgb-trial-211126-1944-003-e0df3111-aws-training-job with trial sm-heart-xgb-trial-2021-11-26-19-42-58.\n",
      "Associating trial component sm-heart-xgb-trial-211126-1944-002-5f1418f4-aws-training-job with trial sm-heart-xgb-trial-2021-11-26-19-42-58.\n"
     ]
    }
   ],
   "source": [
    "# cell09 ... associate HPO Job instances with Trials in parent Experiment\n",
    "\n",
    "import time\n",
    "from datetime import timezone\n",
    "from smexperiments.search_expression import Filter, Operator, SearchExpression\n",
    "\n",
    "# get the most recently created tuning job\n",
    "\n",
    "list_tuning_jobs_response = sm.list_hyper_parameter_tuning_jobs(\n",
    "    SortBy=\"CreationTime\", SortOrder=\"Descending\"\n",
    ")\n",
    "print(f'Found {len(list_tuning_jobs_response[\"HyperParameterTuningJobSummaries\"])} tuning jobs.')\n",
    "tuning_jobs = list_tuning_jobs_response[\"HyperParameterTuningJobSummaries\"]\n",
    "most_recently_created_tuning_job = tuning_jobs[0]\n",
    "\n",
    "creation_time = most_recently_created_tuning_job[\"CreationTime\"]\n",
    "creation_time = creation_time.astimezone(timezone.utc)\n",
    "creation_time = creation_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "created_after_filter = Filter(\n",
    "    name=\"CreationTime\",\n",
    "    operator=Operator.GREATER_THAN_OR_EQUAL,\n",
    "    value=str(creation_time),\n",
    ")\n",
    "source_arn_filter = Filter(\n",
    "    name=\"TrialComponentName\", operator=Operator.CONTAINS, value=trial_prefix\n",
    ")\n",
    "source_type_filter = Filter(\n",
    "    name=\"Source.SourceType\", operator=Operator.EQUALS, value=\"SageMakerTrainingJob\"\n",
    ")\n",
    "\n",
    "search_expression = SearchExpression(\n",
    "    filters=[created_after_filter, source_arn_filter, source_type_filter]\n",
    ")\n",
    "\n",
    "# search for related training trials\n",
    "trial_component_search_results = list(\n",
    "    TrialComponent.search(search_expression=search_expression, sagemaker_boto_client=sm)\n",
    ")\n",
    "print(f\"Found {len(trial_component_search_results)} trial components.\")\n",
    "\n",
    "try:\n",
    "    trial = Trial.load(trial_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        trial = Trial.create(experiment_name=experiment_name, trial_name=trial_name)\n",
    "\n",
    "for tc in trial_component_search_results:\n",
    "    print(f\"Associating trial component {tc.trial_component_name} with trial {trial.trial_name}.\")\n",
    "    trial.add_trial_component(tc.trial_component_name)\n",
    "    # sleep to avoid throttling\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-11-28 03:23:54 Starting - Preparing the instances for training\n",
      "2021-11-28 03:23:54 Downloading - Downloading input data\n",
      "2021-11-28 03:23:54 Training - Training image download completed. Training in progress.\n",
      "2021-11-28 03:23:54 Uploading - Uploading generated training model\n",
      "2021-11-28 03:23:54 Completed - Training job completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sm-heart-xgb-trial-2021-11-28-03-25-35-417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint with name sm-heart-xgb-trial-211128-0320-002-b8569452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# cell 10 ... select best training job per the eval metric\n",
    "# HPO.model.select\n",
    "ml_tuner.best_training_job()\n",
    "# HPO.model.deploy\n",
    "ml_tuner_predictor = ml_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', serializer=sagemaker.serializers.CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11 ... evaluate best model performance\n",
    "test_features = test_data.drop(['target_heart_failure'], axis=1)\n",
    "test_labels = test_data['target_heart_failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.predictor.Predictor object at 0x7f493f672ad0>\n",
      "rows=60, cols=11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.27497214, 0.5       , 0.5       , 0.27497214, 0.31722134,\n",
       "       0.27497214, 0.5       , 0.5       , 0.5       , 0.27497214,\n",
       "       0.27497214, 0.27497214, 0.5       , 0.27497214, 0.27497214,\n",
       "       0.43209249, 0.5       , 0.31722134, 0.5       , 0.5       ,\n",
       "       0.27497214, 0.31722134, 0.27497214, 0.5       , 0.5       ,\n",
       "       0.5       , 0.5       , 0.27497214, 0.27497214, 0.31722134,\n",
       "       0.31722134, 0.5       , 0.5       , 0.31722134, 0.27497214,\n",
       "       0.5       , 0.27497214, 0.5       , 0.27497214, 0.27497214,\n",
       "       0.34287965, 0.27497214, 0.5       , 0.27497214, 0.27497214,\n",
       "       0.27497214, 0.5       , 0.27497214, 0.27497214, 0.38984329,\n",
       "       0.27497214, 0.27497214, 0.5       , 0.27497214, 0.27497214,\n",
       "       0.27497214, 0.27497214, 0.5       , 0.27497214, 0.27497214])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 12 .. run SageMaker Clarify to evaluate model bias and importance of feature attribution\n",
    "def predict(predictor, data, rows=500, verbose=False):\n",
    "    arrays = np.array_split(data, int(data.shape[0] / float(rows)+1))\n",
    "    predictions = ''\n",
    "    for array in arrays:\n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "        \n",
    "    return np.fromstring(predictions[1:],sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions  0.0\n",
       "actual          \n",
       "0             43\n",
       "1             17"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 13 ... analyze predictions on the test data set\n",
    "predictions = predict(ml_tuner_predictor, test_features.to_numpy(), verbose=True)\n",
    "pd.crosstab(index=test_labels, columns=np.round(predictions), rownames=[\"actual\"],colnames=[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell zzz ... cleanup\n",
    "# delete endpoint\n",
    "# delete model\n",
    "# delete s3 bucket"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
