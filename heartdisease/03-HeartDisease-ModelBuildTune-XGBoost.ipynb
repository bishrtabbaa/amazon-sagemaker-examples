{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Heart Disease with Amazon SageMaker XGBoost\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.7/site-packages (0.1.35)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.19.3)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.23.0,>=1.22.3 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.22.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.3->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# cell 00 .. install and setup dependent libraries and SDKs for Jupyter Notebook\n",
    "%pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-2-645411899653\n"
     ]
    }
   ],
   "source": [
    "# cell 01\n",
    "import sagemaker\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html\n",
    "session = sagemaker.Session()\n",
    "s3_bucket = session.default_bucket()\n",
    "s3_data_prefix = 'sagemaker/heartdisease/data/'\n",
    "s3_model_prefix = 'sagemaker/heartdisease/xgboost'\n",
    "s3_output_path = 's3://{}/{}/output'.format(s3_bucket, s3_model_prefix)\n",
    "algorithm = 'xgboost'\n",
    "trial_prefix = 'sm-heart-xgb-trial'\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker',region_name=region)\n",
    "s3 = boto3.Session().resource('s3')\n",
    "\n",
    "print(s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02 ... ETL\n",
    "s3_remote_path = s3_data_prefix + 'heart_failure_clinical_records_data-02-processed.csv'\n",
    "sm_local_path = 'heart_failure_clinical_records_data-02-processed.csv'\n",
    "\n",
    "# download file from remote to local\n",
    "s3.Bucket(s3_bucket).download_file( s3_remote_path, sm_local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_heart_failure</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>age</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.192945</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>1.681648e-02</td>\n",
       "      <td>0.490057</td>\n",
       "      <td>-1.504036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.491279</td>\n",
       "      <td>7.514640</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>7.535660e-09</td>\n",
       "      <td>-0.284552</td>\n",
       "      <td>-0.141976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>-0.449939</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>-1.038073e+00</td>\n",
       "      <td>-0.090900</td>\n",
       "      <td>-1.731046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.912335</td>\n",
       "      <td>-0.486071</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>-5.464741e-01</td>\n",
       "      <td>0.490057</td>\n",
       "      <td>0.085034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>-0.435486</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>6.517986e-01</td>\n",
       "      <td>1.264666</td>\n",
       "      <td>-4.682176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098199</td>\n",
       "      <td>-0.537688</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>-1.109765e+00</td>\n",
       "      <td>-0.284552</td>\n",
       "      <td>1.447094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.491279</td>\n",
       "      <td>1.278215</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>6.802472e-02</td>\n",
       "      <td>-0.187726</td>\n",
       "      <td>0.539054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.333392</td>\n",
       "      <td>1.525979</td>\n",
       "      <td>1.854958</td>\n",
       "      <td>4.902082e+00</td>\n",
       "      <td>-0.575031</td>\n",
       "      <td>0.312044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.333392</td>\n",
       "      <td>1.890398</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>-1.263389e+00</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.766064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.912335</td>\n",
       "      <td>-0.398321</td>\n",
       "      <td>0.585389</td>\n",
       "      <td>1.348231e+00</td>\n",
       "      <td>0.199578</td>\n",
       "      <td>-0.141976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target_heart_failure  sex  smoking  diabetes  anaemia  \\\n",
       "0                       1    1        0         0        0   \n",
       "1                       1    1        0         0        0   \n",
       "2                       1    1        1         0        0   \n",
       "3                       1    1        0         0        1   \n",
       "4                       1    0        0         1        1   \n",
       "..                    ...  ...      ...       ...      ...   \n",
       "294                     0    1        1         1        0   \n",
       "295                     0    0        0         0        0   \n",
       "296                     0    0        0         1        0   \n",
       "297                     0    1        1         0        0   \n",
       "298                     0    1        1         0        0   \n",
       "\n",
       "     high_blood_pressure       age  creatinine_phosphokinase  \\\n",
       "0                      1  1.192945                  0.000166   \n",
       "1                      0 -0.491279                  7.514640   \n",
       "2                      0  0.350833                 -0.449939   \n",
       "3                      0 -0.912335                 -0.486071   \n",
       "4                      0  0.350833                 -0.435486   \n",
       "..                   ...       ...                       ...   \n",
       "294                    1  0.098199                 -0.537688   \n",
       "295                    0 -0.491279                  1.278215   \n",
       "296                    0 -1.333392                  1.525979   \n",
       "297                    0 -1.333392                  1.890398   \n",
       "298                    0 -0.912335                 -0.398321   \n",
       "\n",
       "     ejection_fraction     platelets  serum_creatinine  serum_sodium  \n",
       "0            -1.530560  1.681648e-02          0.490057     -1.504036  \n",
       "1            -0.007077  7.535660e-09         -0.284552     -0.141976  \n",
       "2            -1.530560 -1.038073e+00         -0.090900     -1.731046  \n",
       "3            -1.530560 -5.464741e-01          0.490057      0.085034  \n",
       "4            -1.530560  6.517986e-01          1.264666     -4.682176  \n",
       "..                 ...           ...               ...           ...  \n",
       "294          -0.007077 -1.109765e+00         -0.284552      1.447094  \n",
       "295          -0.007077  6.802472e-02         -0.187726      0.539054  \n",
       "296           1.854958  4.902082e+00         -0.575031      0.312044  \n",
       "297          -0.007077 -1.263389e+00          0.005926      0.766064  \n",
       "298           0.585389  1.348231e+00          0.199578     -0.141976  \n",
       "\n",
       "[299 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 03 ... preview input data frame ... 299 rows x 12 columns\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(sm_local_path)\n",
    "pd.set_option('display.max_columns', 50)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 50)         # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 04 ... split data set into training and test subsets\n",
    "train_data = data.sample(frac=0.8,random_state=200)\n",
    "\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data uploaded to: s3://sagemaker-us-east-2-645411899653/sagemaker/heartdisease/xgboost/train/train_data.csv\n",
      "Test data uploaded to: s3://sagemaker-us-east-2-645411899653/sagemaker/heartdisease/xgboost/test/test_data.csv\n"
     ]
    }
   ],
   "source": [
    "# cell 05 .. publish training and test subsets of data to S3\n",
    "train_file = 'train_data.csv';\n",
    "train_data.to_csv(train_file, index=False, header=False)\n",
    "train_data_s3_path = session.upload_data(path=train_file, key_prefix=s3_model_prefix + \"/train\")\n",
    "print('Train data uploaded to: ' + train_data_s3_path)\n",
    "\n",
    "test_file = 'test_data.csv';\n",
    "test_data.to_csv(test_file, index=False, header=False)\n",
    "test_data_s3_path = session.upload_data(path=test_file, key_prefix=s3_model_prefix + \"/test\")\n",
    "print('Test data uploaded to: ' + test_data_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the SageMaker HyperParameter Tuning Job<a name=\"Launching\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm-heart-exp-2021-12-06-19-06-19\n",
      "sm-heart-xgb-trial-2021-12-06-19-06-19\n"
     ]
    }
   ],
   "source": [
    "# cell 06 ... create parent experiment to associate with HPO tuning job\n",
    "\n",
    "import time\n",
    "from time import strftime\n",
    "\n",
    "import smexperiments\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "experiment_prefix = 'sm-heart-exp' \n",
    "experiment_name = 'sm-heart-exp-{}'.format(create_date)\n",
    "trial_name = '{}-{}'.format(trial_prefix, create_date)\n",
    "\n",
    "# experiment\n",
    "try:\n",
    "    experiment = Experiment.load(experiment_name = experiment_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        experiment = Experiment.create(experiment_name = experiment_name, \n",
    "                                       description = \"SageMaker Heart Disease experiment\", \n",
    "                                       tags = [{'Key': 'Experiment', 'Value': experiment_name}])\n",
    "# trial\n",
    "\n",
    "try:\n",
    "    trial = Trial.load(trial_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        trial = Trial.create(experiment_name=experiment_name, trial_name=trial_name)\n",
    "        \n",
    "print(experiment_name)\n",
    "print(trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined ML model estimator for sm-heart-xgb-trial-2021-12-06-19-06-19\n"
     ]
    }
   ],
   "source": [
    "# cell 07\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "# get algo container [class]\n",
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework=algorithm, version='latest')\n",
    "# setup estimator for algo [tbt running instance of algo class]\n",
    "ml_model = sagemaker.estimator.Estimator(                \n",
    "                container,\n",
    "                role, \n",
    "                instance_count=1, \n",
    "                instance_type='ml.m4.xlarge',\n",
    "                output_path=s3_output_path,\n",
    "                sagemaker_session=session,\n",
    "                tags = [{'Key':'Experiment','Value':experiment_name},{'Key':'Trial','Value':trial_name}],\n",
    "                debugger_hook_config=DebuggerHookConfig(\n",
    "                    s3_output_path = s3_output_path,\n",
    "                    collection_configs = [\n",
    "                        CollectionConfig(name=\"metrics\",parameters={\"save_interval\":\"5\"}),\n",
    "                        CollectionConfig(name=\"predictions\",parameters={\"save_interval\":\"5\"}),\n",
    "                        CollectionConfig(name=\"feature_importance\",parameters={\"save_interval\":\"5\"}),\n",
    "                        CollectionConfig(name=\"average_shap\", parameters={\"save_interval\":\"5\"})\n",
    "                    ]\n",
    "                )                  \n",
    ")\n",
    "\n",
    "# setup training and test/validation channels\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(s3_bucket, s3_model_prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/test/'.format(s3_bucket, s3_model_prefix), content_type='csv')\n",
    "print('Defined ML model estimator for {}'.format(trial_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sm-heart-xgb-trial-211206-1907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined ML model HPO job for sm-heart-xgb-trial\n",
      ".............................................!\n"
     ]
    }
   ],
   "source": [
    "#cell 08 ... HPO.Job.Run()\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "ml_model.set_hyperparameters( num_round = 100)\n",
    "\n",
    "# define hyperparameter ranges\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html ... alpha, min_child_weight, eta, num_round\n",
    "hyperparameter_ranges = {'eta': ContinuousParameter(0, 1),\n",
    "                            'min_child_weight': ContinuousParameter(1, 10),\n",
    "                            'alpha': ContinuousParameter(0, 100),\n",
    "                            'max_depth': IntegerParameter(1, 10)}\n",
    "\n",
    "# define metric ... F1 = harmonic mean of precision and recall\n",
    "objective_metric_name = 'validation:auc'\n",
    "\n",
    "# define HPO job\n",
    "ml_tuner = HyperparameterTuner(ml_model,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=2,\n",
    "                            base_tuning_job_name = trial_prefix,\n",
    "                           tags = [{'Key':'Experiment','Value':experiment_name},{'Key':'Trial','Value':trial_name}])\n",
    "\n",
    "print('Defined ML model HPO job for {}'.format(trial_prefix))\n",
    "\n",
    "# job.Run()\n",
    "ml_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tuning jobs.\n",
      "Found 2 trial components.\n",
      "Associating trial component sm-heart-xgb-trial-211206-1907-002-5d59fd5a-aws-training-job with trial sm-heart-xgb-trial-2021-12-06-19-06-19.\n",
      "Associating trial component sm-heart-xgb-trial-211206-1907-001-9bb588ee-aws-training-job with trial sm-heart-xgb-trial-2021-12-06-19-06-19.\n"
     ]
    }
   ],
   "source": [
    "# cell09 ... associate HPO Job instances with Trials in parent Experiment\n",
    "\n",
    "import time\n",
    "from datetime import timezone\n",
    "from smexperiments.search_expression import Filter, Operator, SearchExpression\n",
    "\n",
    "# get the most recently created tuning job\n",
    "\n",
    "list_tuning_jobs_response = sm.list_hyper_parameter_tuning_jobs(\n",
    "    SortBy=\"CreationTime\", SortOrder=\"Descending\"\n",
    ")\n",
    "print(f'Found {len(list_tuning_jobs_response[\"HyperParameterTuningJobSummaries\"])} tuning jobs.')\n",
    "tuning_jobs = list_tuning_jobs_response[\"HyperParameterTuningJobSummaries\"]\n",
    "most_recently_created_tuning_job = tuning_jobs[0]\n",
    "\n",
    "creation_time = most_recently_created_tuning_job[\"CreationTime\"]\n",
    "creation_time = creation_time.astimezone(timezone.utc)\n",
    "creation_time = creation_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "created_after_filter = Filter(\n",
    "    name=\"CreationTime\",\n",
    "    operator=Operator.GREATER_THAN_OR_EQUAL,\n",
    "    value=str(creation_time),\n",
    ")\n",
    "source_arn_filter = Filter(\n",
    "    name=\"TrialComponentName\", operator=Operator.CONTAINS, value=trial_prefix\n",
    ")\n",
    "source_type_filter = Filter(\n",
    "    name=\"Source.SourceType\", operator=Operator.EQUALS, value=\"SageMakerTrainingJob\"\n",
    ")\n",
    "\n",
    "search_expression = SearchExpression(\n",
    "    filters=[created_after_filter, source_arn_filter, source_type_filter]\n",
    ")\n",
    "\n",
    "# search for related training trials\n",
    "trial_component_search_results = list(\n",
    "    TrialComponent.search(search_expression=search_expression, sagemaker_boto_client=sm)\n",
    ")\n",
    "print(f\"Found {len(trial_component_search_results)} trial components.\")\n",
    "\n",
    "try:\n",
    "    trial = Trial.load(trial_name)\n",
    "except Exception as ex:\n",
    "    if \"ResourceNotFound\" in str(ex):\n",
    "        trial = Trial.create(experiment_name=experiment_name, trial_name=trial_name)\n",
    "\n",
    "for tc in trial_component_search_results:\n",
    "    print(f\"Associating trial component {tc.trial_component_name} with trial {trial.trial_name}.\")\n",
    "    trial.add_trial_component(tc.trial_component_name)\n",
    "    # sleep to avoid throttling\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-12-06 19:11:04 Starting - Preparing the instances for training\n",
      "2021-12-06 19:11:04 Downloading - Downloading input data\n",
      "2021-12-06 19:11:04 Training - Training image download completed. Training in progress.\n",
      "2021-12-06 19:11:04 Uploading - Uploading generated training model\n",
      "2021-12-06 19:11:04 Completed - Training job completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sm-heart-xgb-trial-2021-12-06-19-11-46-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint with name sm-heart-xgb-trial-211206-1907-002-5d59fd5a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "# cell 10 ... select best training job per the eval metric\n",
    "# HPO.model.select\n",
    "ml_tuner.best_training_job()\n",
    "# HPO.model.deploy\n",
    "ml_tuner_predictor = ml_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', serializer=sagemaker.serializers.CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11 ... evaluate best model performance\n",
    "test_features = test_data.drop(['target_heart_failure'], axis=1)\n",
    "test_labels = test_data['target_heart_failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12 .. calculate predictions for XGBoost\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def predict(predictor, data, rows=500, verbose=False):\n",
    "    predictions = ''\n",
    "    for row in data:\n",
    "        if (verbose):\n",
    "            print(row)\n",
    "        prediction = predictor.predict(row, initial_args={\"ContentType\":\"text/csv\"})\n",
    "        if (verbose):\n",
    "            print(prediction)\n",
    "        predictions = ','.join([predictions, prediction.decode('utf-8')])\n",
    "\n",
    "#    arrays = np.array_split(data[0], 100)\n",
    "#    predictions = ''\n",
    "#    for array in arrays:\n",
    "#        prediction = predictor.predict(array, initial_args={\"ContentType\":\"text/csv\"})\n",
    "#        predictions = ','.join([predictions, prediction.decode('utf-8')])\n",
    "        \n",
    "    return np.fromstring(predictions[1:],sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0.4420003294944763'\n",
      "[0.44200033 0.5        0.5        0.44200033 0.44200033 0.44200033\n",
      " 0.5        0.5        0.5        0.44200033 0.44200033 0.44200033\n",
      " 0.5        0.44200033 0.44200033 0.44200033 0.5        0.44200033\n",
      " 0.5        0.5        0.44200033 0.44200033 0.44200033 0.5\n",
      " 0.5        0.5        0.5        0.44200033 0.44200033 0.44200033\n",
      " 0.44200033 0.5        0.5        0.44200033 0.44200033 0.5\n",
      " 0.44200033 0.5        0.44200033 0.44200033 0.44200033 0.44200033\n",
      " 0.5        0.44200033 0.44200033 0.44200033 0.5        0.44200033\n",
      " 0.44200033 0.44200033 0.44200033 0.44200033 0.5        0.44200033\n",
      " 0.44200033 0.44200033 0.44200033 0.5        0.44200033 0.44200033]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions  0.0\n",
       "actual          \n",
       "0             43\n",
       "1             17"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 13 ... analyze confusion matrix on the test data set\n",
    "result = ml_tuner_predictor.predict([1,0,0,0,0,-0.491279276,7.514639529,-0.00707675,7.54E-09,-0.284552352,-0.141976151], initial_args={\"ContentType\":\"text/csv\"})\n",
    "print(result)\n",
    "\n",
    "# print (test_features)\n",
    "predictions = predict(ml_tuner_predictor, test_features.to_numpy(), verbose=False)\n",
    "\n",
    "# print predictions\n",
    "print(predictions)\n",
    "\n",
    "# calculate confusion matrix\n",
    "pd.crosstab(index=test_labels, columns=np.round(predictions), rownames=[\"actual\"],colnames=[\"predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-896e6d45be0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1 = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1670\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# cell calculate classification metrics\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('Precision = {}'.format(precision_score(test_labels, predictions, average='weighted', zero_division=1)))\n",
    "print('Recall = {}'.format(recall_score(test_labels, predictions, average='weighted', zero_division=1)))\n",
    "print('F1 = {}'.format(f1_score(test_labels, predictions, average='weighted', zero_division=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell zzz ... cleanup\n",
    "# delete endpoint\n",
    "# delete model\n",
    "# delete s3 bucket"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
